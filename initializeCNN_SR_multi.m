function net = initializeCNN_SR_multi(size_input,layer,fn_in)

% size_input = 8;

% fn_in = [filter_size, 1, filter_channel; % N layers
%     filter_size, filter_channel, filter_channel;
%     filter_size, filter_channel, filter_channel;
%     filter_size, filter_channel, filter_channel;
%     filter_size, filter_channel, 1];

net.meta.inputSize = [size_input size_input 1 1] ;

net.layers = { } ;

f=1/100;
for l_n = 1:(layer-1)
    name_conv = sprintf('conv%d',l_n);
    name_relu = sprintf('relu%d',l_n);
    
    net.layers{end+1} = struct(...
        'name', name_conv, ...
        'type', 'conv', ...
        'weights', {{f*randn(fn_in(l_n,1),fn_in(l_n,1),fn_in(l_n,2),fn_in(l_n,3), 'single'), zeros(1, fn_in(l_n,3), 'single')}}, ...
        'pad', 1, ...
        'stride', 1, ...
        'learningRate', [1 1], ...
        'weightDecay', [1 0]) ;
    
    net.layers{end+1} = struct(...
        'name', name_relu, ...
        'type', 'relu') ;
end
% last layer
name_conv = sprintf('conv%d',layer);
net.layers{end+1} = struct(...
    'name', name_conv, ...
    'type', 'conv', ...
    'weights',  {{f*randn(fn_in(layer,1),fn_in(layer,1),fn_in(layer,2),fn_in(layer,3), 'single'), zeros(1, fn_in(layer,3), 'single')}}, ...
    'pad', 1, ...
    'stride', 1, ...
    'learningRate', [1 1], ...
    'weightDecay', [1 0]) ;


% Consolidate the network, fixing any missing option
% in the specification above

net = vl_simplenn_tidy(net) ;